{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project_draft.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Koz3mYWLl-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36e60b1-ccc4-4dc8-c0c4-2c345ee7d55e"
      },
      "source": [
        "import pandas as pd    # to load dataset\n",
        "import numpy as np     # for mathematic equation\n",
        "from nltk.corpus import stopwords   # to get collection of stopwords\n",
        "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
        "from tensorflow.keras.models import Sequential     # the model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
        "from tensorflow.keras.models import load_model   # load saved model\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import keras\n",
        "import keras_metrics\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, SpatialDropout1D\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing import sequence,text\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,f1_score"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxC7UONqNAsU",
        "outputId": "8bf83ba2-652f-45e7-bde7-708854fdfbc9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqpkJ141NQQ0",
        "outputId": "ed37f6b0-67dd-4d03-c734-0d3def3e7775"
      },
      "source": [
        "%cd MyDrive/Colab\\ Notebooks"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaNTX91tNX8R",
        "outputId": "418db652-48f1-4c4a-a93b-44943e14da51"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'IMDB Dataset.csv'   NLP_Project_draft.ipynb   Untitled0.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY8kR0GCMkiM"
      },
      "source": [
        "data = pd.read_csv('IMDB Dataset.csv')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4goLN1-iNY8U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "b51f14c3-1702-46a6-f76a-cc65e74c69ce"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp_g_099SJUV"
      },
      "source": [
        "X = data['review']\n",
        "y = data['sentiment']"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzVslH3-SxWZ"
      },
      "source": [
        "Removing html and symbols from reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt9msWOuSe8d"
      },
      "source": [
        "X = X.replace({'<.*?>': ''}, regex = True)\n",
        "X = X.replace({'[^A-Za-z]': ' '}, regex = True)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0TiRtO7U7bH"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP7716dVThsH"
      },
      "source": [
        "Removing stop words and tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO6YcHDOThAn"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "for i in range(len(X)):\n",
        "  X[i]=word_tokenize(X[i])\n",
        "  X[i] = [w for w in X[i] if not w.lower() in stop_words]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4o9OwejVWR0"
      },
      "source": [
        "Encoding sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enRVcAWsVQGA"
      },
      "source": [
        "y = y.replace('positive', 1)\n",
        "y = y.replace('negative', 0)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX_rUKruV2Y-"
      },
      "source": [
        "Split into 80:20 ratio "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYF7mFsDVsOJ"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZhmDrMqaRW0"
      },
      "source": [
        "unique_word = len(np.unique(x_train))\n",
        "print(unique_word)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXPIuxjlWmRh"
      },
      "source": [
        "Calculating maximum length of the given reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep8DpwXQV_gp",
        "outputId": "e642402a-7fdf-422d-afe6-f2ee06d3b03b"
      },
      "source": [
        "length = []\n",
        "for i in x_train:\n",
        "  length.append(len(i))\n",
        "max_length = int(np.ceil(np.mean(length)))\n",
        "print(max_length)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkE7xjuiXI3L"
      },
      "source": [
        "Tokenizing and padding for model input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVE8CeFVWx0x"
      },
      "source": [
        "token = Tokenizer(lower=False) \n",
        "token.fit_on_texts(x_train)\n",
        "\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feh5cXWycyKW"
      },
      "source": [
        "total_words = len(token.word_index) + 1"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pQABdxxXZNK",
        "outputId": "77a07802-bfec-427f-daa0-efb8a90f020f"
      },
      "source": [
        "x_train"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3136,  983,  357, ...,    0,    0,    0],\n",
              "       [ 318, 4109,  459, ...,    0,    0,    0],\n",
              "       [  13,  105,    2, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 158,  327, 3293, ...,   36,  438, 3169],\n",
              "       [1661,  279,  473, ...,    0,    0,    0],\n",
              "       [  92,   45,  210, ..., 1406,   24,   92]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26ltkMZzXgxU"
      },
      "source": [
        "CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXRiwUGaXcPy",
        "outputId": "dad1c1be-8e58-4419-cfec-a089fa8cb42d"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(unique_word, 150, input_length = max_length))\n",
        "model.add(Conv1D(32,kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.summary()\n",
        "model.add(Dense(2, activation='sigmoid'))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 119, 150)          5961300   \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 119, 32)           14432     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 59, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 59, 64)            6208      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 29, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 29, 64)            12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 14, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 14, 64)            12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 7, 64)             0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 448)               0         \n",
            "=================================================================\n",
            "Total params: 6,006,644\n",
            "Trainable params: 6,006,644\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9dsz-2SZF60"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adamax', metrics=['accuracy'])"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoXfKzHwceEm",
        "outputId": "4fab2f3f-9b85-437a-d273-5dd70365d045"
      },
      "source": [
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 119) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcNvXCMebU89"
      },
      "source": [
        "#model.fit(x_train, y_train, batch_size = 128, epochs = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i73bNH6kcnud"
      },
      "source": [
        "LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zchJjVYqcnLu",
        "outputId": "208c0549-f5bb-48ef-b733-05b656656e70"
      },
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Embedding(total_words, 32, input_length = max_length))\n",
        "model1.add(LSTM(64))\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "model1.compile(optimizer = 'adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "print(model1.summary())"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 119, 32)           3748192   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 3,773,089\n",
            "Trainable params: 3,773,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG18NCdNc8IG"
      },
      "source": [
        "#model.fit(x_train, y_train, batch_size = 128, epochs = 10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}